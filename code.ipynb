{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0588d18d-49ee-4fc5-87e5-8193a3e792a4",
   "metadata": {},
   "source": [
    "# Gradients without backpropagation\n",
    "\n",
    "Here I'm testing their approach using a simple regression model $h(\\theta,X) = \\theta_0 + \\theta_1x_0 + \\theta_2x_1$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594f552c-78d1-4601-89be-b0929313362b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True derivative\n",
      "[0.80854047 0.49895263 0.55537556]\n",
      "*******\n",
      "Estimated derivative\n",
      "[0.8041822168887169, 0.49626311208377466, 0.5523819027735966]\n"
     ]
    }
   ],
   "source": [
    "# Simple script that runs my forward gradient\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def hypothesis(X, theta):\n",
    "    \"\"\"\n",
    "    h = theta_1@x + theta_0\n",
    "    \"\"\"\n",
    "    return theta[0] + X@theta[1:]\n",
    "\n",
    "\n",
    "def mse_loss(X, y, theta): \n",
    "    \"\"\"\n",
    "    MSE loss: ((h(x)-y)**2)/2n\n",
    "    \"\"\"   \n",
    "    return np.mean((hypothesis(X, theta) - y)**2) / 2\n",
    "\n",
    "\n",
    "def mse_loss_derivative(X, y, theta):\n",
    "    \"\"\"\n",
    "    MSE derivative: [((h(x)-y))]\n",
    "    \"\"\"   \n",
    "    \n",
    "    d_theta_0 = np.mean(hypothesis(X, theta) - y)\n",
    "    d_theta_N = X.T@(hypothesis(X, theta) - y) / len(X)\n",
    "    return np.concatenate(([d_theta_0], d_theta_N))\n",
    "    \n",
    "\n",
    "def mse_estimated_derivative(X,y,theta, h=1e-10, n_v=100000):\n",
    "    \n",
    "    estimated_theta = []\n",
    "\n",
    "    V = np.random.normal(0,1, n_v) # ~N(0,1)\n",
    "    h_V = h*V\n",
    "\n",
    "    # Estimating the partial derivative for each theta: https://en.wikipedia.org/wiki/Partial_derivative\n",
    "    for i,t in enumerate(theta):\n",
    "\n",
    "\n",
    "        # | t_0, t_1+h*v_0, t_2\n",
    "        # | t_0, t_1+h*v_1, t_2\n",
    "        # | t_0, t_1+h*v_n, t_2\n",
    "        thetas= np.tile(theta, n_v).reshape(n_v,theta.shape[0])\n",
    "        thetas[:, i] += h_V\n",
    "\n",
    "        \n",
    "        e_theta = [ ((mse_loss(X, y, t) - mse_loss(X, y, theta))/h)*v  for v,t in zip(V,thetas)] # Definicao de derivada        \n",
    "        e_theta = np.mean(e_theta) # averaging\n",
    "\n",
    "        estimated_theta.append(e_theta)\n",
    "        pass\n",
    "\n",
    "    return estimated_theta        \n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(10,2)\n",
    "y = np.random.rand(10)\n",
    "theta = np.array([1,0.5,0.2])\n",
    "\n",
    "print(\"True derivative\")\n",
    "print(mse_loss_derivative(X,y,theta))\n",
    "print(\"*******\")\n",
    "print(\"Estimated derivative\")\n",
    "print(mse_estimated_derivative(X,y,theta, n_v=100000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db1f27-4282-4613-984f-3466ac47237d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
